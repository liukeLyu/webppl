<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from probmods.org/chapters/dependence.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 04 Feb 2020 14:08:27 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Causal and statistical dependence</title>

    <link rel="stylesheet" href="../assets/css/bootstrap.min.css">
    <link rel="stylesheet" href="../assets/css/bootstrap-theme.min.css">
    <link rel="stylesheet" href="../assets/css/default.css">
    <link href="https://fonts.googleapis.com/css?family=Crimson+Text|Inconsolata" rel="stylesheet">
    <script src="../assets/js/ga.js"></script>
    <script src="../assets/js/jquery.min.js"></script>
    <script type="text/javascript" src="../assets/js/bootstrap.min.js"></script>

<!--    <script src="/assets/js/underscore-min.js"></script> 
    <script src="https://probmods.org/bower_components/underscore/underscore.js"></script> -->

    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    
      
      <link rel="stylesheet" href="../assets/css/katex.min.css" media="screen" type="text/css">
      
      <link rel="stylesheet" href="../assets/css/littlefoot.css" media="screen" type="text/css">
      
      <link rel="stylesheet" href="../assets/css/webppl-viz.css" media="screen" type="text/css">
      
      <link rel="stylesheet" href="../assets/css/webppl-editor.css" media="screen" type="text/css">
      
    
    
    
    
      
      <script src='../assets/js/katex.min.js' type="text/javascript"></script>
      
      <script src='../assets/js/littlefoot.min.js' type="text/javascript"></script>
      
      <script src='../assets/js/paper-full.js' type="text/javascript"></script>
      
      <script src='../assets/js/parse-bibtex.js' type="text/javascript"></script>
      
      <script src='../assets/js/chapter.js' type="text/javascript"></script>
      
    
    
    
    
  </head>
  <body>

    

    <div class="container">
      <ul class="nav navbar-nav">
        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">&#9776;</a>
          <ul class="dropdown-menu">
            <li><a href="../index.html">Home</a></li>
            <li role="separator" class="divider"></li>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <li><a href="introduction.html">Introduction</a></li>
            
            
            
            <li><a href="generative-models.html">Generative models</a></li>
            
            
            
            <li><a href="conditioning.html">Conditioning</a></li>
            
            
            
            <li><a href="dependence.html">Causal and statistical dependence</a></li>
            
            
            
            <li><a href="conditional-dependence.html">Conditional dependence</a></li>
            
            
            
            <li><a href="bayesian-data-analysis.html">Bayesian data analysis</a></li>
            
            
            
            <li><a href="inference-algorithms.html">Algorithms for inference</a></li>
            
            
            
            <li><a href="process-models.html">Rational process models</a></li>
            
            
            
            <li><a href="learning-as-conditional-inference.html">Learning as conditional inference</a></li>
            
            
            
            <li><a href="lot-learning.html">Learning with a language of thought</a></li>
            
            
            
            <li><a href="hierarchical-models.html">Hierarchical models</a></li>
            
            
            
            <li><a href="occams-razor.html">Occam's Razor</a></li>
            
            
            
            <li><a href="function-learning.html">Learning (deep) continuous functions</a></li>
            
            
            
            <li><a href="mixture-models.html">Mixture models</a></li>
            
            
            
            <li><a href="social-cognition.html">Social cognition</a></li>
            
            
            
            <li><a href="appendix-js-basics.html">Appendix - JavaScript basics</a></li>
            
            
            
            <li><a href="appendix-useful-distributions.html">Appendix - Useful distributions</a></li>
            
            
          </ul>
        </li>
      </ul>

      <div class="page-header">
  <h1>Causal and statistical dependence</h1>
</div>

<h1 id="causal-dependence">Causal Dependence</h1>

<p>Probabilistic programs encode knowledge about the world in the form of causal models, and it is useful to understand how their function relates to their structure by thinking about some of the intuitive properties of causal relations.
Causal relations are local, modular, and directed.
They are <em>modular</em> in the sense that any two arbitrary events in the world are most likely causally unrelated, or independent.
If they are related, or dependent, the relation is only very weak and liable to be ignored in our mental models.
Causal structure is <em>local</em> in the sense that many events that are related are not related directly: They are connected only through causal chains of several steps, a series of intermediate and more local dependencies.
And the basic dependencies are <em>directed</em>: when we say that A causes B, it means something different than saying that B causes A.
The <em>causal influence</em> flows only one way along a causal relation—we expect that manipulating the cause will change the effect, but not vice versa—but <em>information</em> can flow both ways—learning about either event will give us information about the other.</p>

<p>Let’s examine this notion of “causal dependence” a little more carefully.
 What does it mean to believe that A depends causally on B?  Viewing cognition through the lens of probabilistic programs, the most basic notions of causal dependence are in terms of the structure of the program and the flow of evaluation (or “control”) in its execution.
We say that expression A causally depends on expression B if it is necessary to evaluate B in order to evaluate A.
(More precisely, expression A depends on expression B if it is ever necessary to evaluate B in order to evaluate A.) For instance, in this program <code class="highlighter-rouge">A</code> depends on <code class="highlighter-rouge">B</code> but not on <code class="highlighter-rouge">C</code> (the final expression depends on both <code class="highlighter-rouge">A</code> and <code class="highlighter-rouge">C</code>):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var C = flip()
var B = flip()
var A = B ? flip(0.1) : flip(0.4)
A || C
</code></pre></div></div>

<p>Note that causal dependence order is weaker than a notion of ordering in time—one expression might happen to be evaluated before another in time (for instance <code class="highlighter-rouge">C</code> before <code class="highlighter-rouge">A</code>), but without the second expression requiring the first.
(This notion of causal dependence is related to the notion of <a href="https://en.wikipedia.org/wiki/Dependence_analysis">flow dependence</a> in the programming language literature.)</p>

<p>For example, consider a simpler variant of our medical diagnosis scenario:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var marg = Infer({method: 'enumerate'}, function() {
  var smokes = flip(0.2)
  var lungDisease = (smokes &amp;&amp; flip(0.1)) || flip(0.001)
  var cold = flip(0.02)
  var cough = (cold &amp;&amp; flip(0.5)) || (lungDisease &amp;&amp; flip(0.5)) || flip(0.001)
  var fever = (cold &amp;&amp; flip(0.3)) || flip(0.01)
  var chestPain = (lungDisease &amp;&amp; flip(0.2)) || flip(0.01)
  var shortnessOfBreath = (lungDisease &amp;&amp; flip(0.2)) || flip(0.01)

  condition(cough)
  return {cold: cold, lungDisease: lungDisease}
})

viz.marginals(marg)
</code></pre></div></div>

<p>Here, <code class="highlighter-rouge">cough</code> depends causally on both <code class="highlighter-rouge">lungDisease</code> and <code class="highlighter-rouge">cold</code>, while <code class="highlighter-rouge">fever</code> depends causally on <code class="highlighter-rouge">cold</code> but not <code class="highlighter-rouge">lungDisease</code>.
We can see that <code class="highlighter-rouge">cough</code> depends causally on <code class="highlighter-rouge">smokes</code> but only indirectly: although <code class="highlighter-rouge">cough</code> does not call <code class="highlighter-rouge">smokes</code> directly, in order to evaluate whether a patient coughs, we first have to evaluate the expression <code class="highlighter-rouge">lungDisease</code> that must itself evaluate <code class="highlighter-rouge">smokes</code>.</p>

<p>We haven’t made the notion of “direct” causal dependence precise: do we want to say that <code class="highlighter-rouge">cough</code> depends directly on <code class="highlighter-rouge">cold</code>, or only directly on the expression <code class="highlighter-rouge">(cold &amp;&amp; flip(0.5)) || ...</code>? This can be resolved in several ways that all result in similar intuitions.
For instance, we could first re-write the program into a form where each intermediate expression is named (called A-normal form) and then say direct dependence is when one expression immediately includes the name of another.</p>

<p>There are several special situations that are worth mentioning.
In some cases, whether expression A requires expression B will depend on the value of some third expression C.
 For example, here is a particular way of writing a noisy-AND relationship:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var C = flip()
var B = flip()
var A = (C ?
         (B ? flip(.85) : false) :
         false)
A
</code></pre></div></div>

<p>A always requires C, but only evaluates B if C returns true.
Under the above definition of causal dependence A depends on B (as well as C).
However, one could imagine a more fine-grained notion of causal dependence that would be useful here: we could say that A depends causally on B only in certain <em>contexts</em> (just those where C happens to return true and thus A calls B).</p>

<p>Another nuance is that an expression that occurs inside a function body may get evaluated several times in a program execution.
In such cases it is useful to speak of causal dependence between specific evaluations of two expressions.
(However, note that if a specific evaluation of A depends on a specific evaluation of B, then any other specific evaluation of A will depend on <em>some</em> specific evaluation of B.
Why?)</p>

<h2 id="detecting-dependence-through-intervention">Detecting Dependence Through Intervention</h2>

<p>The causal dependence structure is not always immediately clear from examining a program, particularly where there are complex functions calls.
Another way to detect (or according to some philosophers, such as Jim Woodward, to <em>define</em>) causal dependence is more operational, in terms of “difference making”: If we manipulate A, does B tend to change? By <em>manipulate</em> here we don’t mean an assumption in the sense of <code class="highlighter-rouge">condition</code>.
Instead we mean actually edit, or <em>intervene on</em>, the program in order to make an expression have a particular value independent of its (former) causes.
If setting A to different values in this way changes the distribution of values of B, then B causally depends on A.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var BdoA = function(Aval) {
  return Infer({method: 'enumerate'}, function() {
    var C = flip()
    var A = Aval //we directly set A to the target value
    var B = A ? flip(.1) : flip(.4)
    return {B: B}
  })
}

viz(BdoA(true))
viz(BdoA(false))
</code></pre></div></div>

<p>This method is known in the causal Bayesian network literature as the “do operator” or graph surgery (Pearl, 1988).
It is also the basis for interesting theories of counterfactual reasoning by Pearl and colleagues (Halpern, Hitchcock and others).</p>

<p>For example, this code represents whether a patient is likely to have a cold or a cough <em>a priori</em>, without conditions or observations:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var medicalDist = Infer({method: 'enumerate'}, function() {
  var smokes = flip(.2)
  var lungDisease = flip(0.001) || (smokes &amp;&amp; flip(0.1))
  var cold = flip(0.02)

  var cough = (cold &amp;&amp; flip(0.5)) || (lungDisease &amp;&amp; flip(0.5)) || flip(0.001)
  var fever = (cold &amp;&amp; flip(0.3)) || flip(0.01)
  var chestPain = (lungDisease &amp;&amp; flip(0.2)) || flip(0.01)
  var shortnessOfBreath = (lungDisease &amp;&amp; flip(0.2)) || flip(0.01)

  return {cough: cough, cold: cold}
})
viz.marginals(medicalDist)
</code></pre></div></div>

<p>Imagine we now <em>give</em> our hypothetical patient a  cold—for example, by exposing him to a strong cocktail of cold viruses.
We should not model this as an observation (e.g. by conditioning on having a cold), because we have taken direct action to change the normal causal structure.
Instead we implement intervention by directly editing the program: try to first do <code class="highlighter-rouge">var cold = true</code>, then do <code class="highlighter-rouge">var cold = false</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var medicalDist = Infer({method: 'enumerate'}, function() {
  var smokes = flip(.2)
  var lungDisease = flip(0.001) || (smokes &amp;&amp; flip(0.1))
  var cold = true // we intervene to make cold true

  var cough = (cold &amp;&amp; flip(0.5)) || (lungDisease &amp;&amp; flip(0.5)) || flip(0.001)
  var fever = (cold &amp;&amp; flip(0.3)) || flip(0.01)
  var chestPain = (lungDisease &amp;&amp; flip(0.2)) || flip(0.01)
  var shortnessOfBreath = (lungDisease &amp;&amp; flip(0.2)) || flip(0.01)

  return {cough: cough, cold: cold}
})
viz.marginals(medicalDist)
</code></pre></div></div>

<p>You should see that the distribution on <code class="highlighter-rouge">cough</code> changes: coughing becomes more likely if we know that a patient has been given a cold by external intervention.
But the reverse is not true:
Try forcing the patient to have a  cough (e.g., with some unusual drug or by exposure to some cough-inducing dust) by writing <code class="highlighter-rouge">var cough = true</code>: the distribution on <code class="highlighter-rouge">cold</code> is unaffected.
We have captured a familiar fact: treating the symptoms of a disease directly doesn’t cure the disease (taking cough medicine doesn’t make your cold go away), but treating the disease <em>does</em> relieve the symptoms.</p>

<p>Verify in the program above that the method of manipulation works also to identify causal relations that are only indirect: for example, force a patient to smoke and show that it increases their probability of coughing, but not vice versa.</p>

<p>If we are given a program representing a causal model, and the model is simple enough, it is straightforward to read off causal dependencies from the program code itself.
However, the notion of causation as difference-making may be easier to compute in much larger, more complex models—and it does not require an analysis of the program code.
As long as we can modify (or imagine modifying) the definitions in the program and can run the resulting model, we can compute whether two events or functions are causally related by the difference-making criterion.</p>

<h1 id="statistical-dependence">Statistical Dependence</h1>

<p>One often hears the warning, “correlation does not imply causation”.
By “correlation” we mean a different kind of dependence between events or functions—<em>statistical dependence</em>.
We say that A and B are statistically dependent, if learning information about A tells us something about B, and vice versa.
In the language of webppl: using <code class="highlighter-rouge">condition</code> to make an assumption about A changes the value expected for B.
Statistical dependence is a <em>symmetric</em> relation between events referring to how information flows between them when we observe or reason about them.
(If conditioning on A changes B, then conditioning on B also changes A.
Why?)
The fact that we need to be warned against confusing statistical and causal dependence suggests they are related, and indeed, they are.
In general, if A causes B, then A and B will be statistically dependent.
(One might even say the two notions are “causally related”, in the sense that causal dependencies give rise to statistical dependencies.)</p>

<p>Diagnosing statistical dependence using <code class="highlighter-rouge">condition</code> is similar to diagnosing causal dependence through intervention. We condition on various values of the possible statistical dependent, here <code class="highlighter-rouge">A</code>, and see whether it changes the distribution on the target, here <code class="highlighter-rouge">B</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var BcondA = function(Aval) {
  return Infer({method: 'enumerate'}, function() {
    var C = flip()
    var A = flip()
    var B = A ? flip(.1) : flip(.4)
    condition(A == Aval) //condition on new information about A
    return {B: B}
  })
}

viz(BcondA(true))
viz(BcondA(false))
</code></pre></div></div>

<p>Because the two distributions on <code class="highlighter-rouge">B</code> (when we have different information about <code class="highlighter-rouge">A</code>) are different, we can conclude that <code class="highlighter-rouge">B</code> statistically depends on <code class="highlighter-rouge">A</code>.
Do the same procedure for testing if <code class="highlighter-rouge">A</code> statistically depends on <code class="highlighter-rouge">B</code>.
How is this similar (and different) from the causal dependence between these two?
As an exercise, make a version of the above medical example to test the statistical dependence between <code class="highlighter-rouge">cough</code> and <code class="highlighter-rouge">cold</code>.
Verify that statistical dependence holds symmetrically for events that are connected by an indirect causal chain, such as <code class="highlighter-rouge">smokes</code> and <code class="highlighter-rouge">coughs</code>.</p>

<p>Correlation is not just a symmetrized version of causality.
Two events may be statistically dependent even if there is no causal chain running between them, as long as they have a common cause (direct or indirect).
That is, two expressions in a WebPPL program can be statistically dependent if one calls the other, directly or indirectly, <em>or</em> if they both at some point in their evaluation histories refer to some other expression (a “common cause”).
Here is an example of statistical dependence generated by a common cause:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var BcondA = function(Aval) {
  return Infer({method: 'enumerate'}, function() {
    var C = flip();
    var A = C ? flip(.5) : flip(.9);
    var B = C ? flip(.1) : flip(.4);
    condition(A == Aval);
    return {B: B};
  })
}

viz(BcondA(true))
viz(BcondA(false))
</code></pre></div></div>

<p>Situations like this are extremely common.
In the medical example above, <code class="highlighter-rouge">cough</code> and <code class="highlighter-rouge">fever</code> are not causally dependent but they are statistically dependent, because they both depend on <code class="highlighter-rouge">cold</code>; likewise for <code class="highlighter-rouge">chestPain</code> and <code class="highlighter-rouge">shortnessOfBreath</code> which both depend on <code class="highlighter-rouge">lungDisease</code>.
Here we can read off these facts from the program definitions, but more generally all of these relations can be diagnosed by reasoning using <code class="highlighter-rouge">Infer</code>.</p>

<p>Successful learning and reasoning with causal models typically depends on exploiting the close coupling between causation and correlation.
Causal relations are typically unobservable, while correlations are observable from data.
Noticing patterns of correlation is thus often the beginning of causal learning, or discovering what causes what.
On the other hand, with a causal model already in place, reasoning about the statistical dependencies implied by the model allows us to predict many aspects of the world not directly observed from those aspects we do observe.</p>

<h1 id="graphical-notations-for-dependence">Graphical Notations for Dependence</h1>

<p><em>Graphical models</em> are an extremely important idea in modern machine learning: a graphical diagram is used to represent the direct dependence structure between random choices in a probabilistic model.
A special case are <em>Bayesian networks</em>, in which there is a node for each random variable (an expression in our terms) and a link between two nodes if there is a direct conditional dependence between them (a direct causal dependence in our terms).
The sets of nodes and links define a <em>directed acyclic graph</em> (hence the term graphical model), a data structure over which many efficient algorithms can be defined.
Each node has a <em>conditional probability table</em> (CPT), which represents the probability distribution of that node, given values of its parents.
The joint probability distribution over random variables is given by the product of the conditional distributions for each variable in the graph.</p>

<p>The figure below defines a Bayesian network for the medical diagnosis example.
The graph contains a node for each <code class="highlighter-rouge">var</code> statement in our WebPPL program, with links to that node from each variable that appears in the assignment expression.
There is a probability table (“CPT”) for each node, with a column for each value of the variable, and a row for each combination of values for its parents in the graph.</p>

<p><img src="../assets/img/Med-diag-bnet1.jpg" alt="A Bayes net for the medical diagnosis example." /></p>

<p>Simple generative models will have a corresponding graphical model that captures all of the dependencies (and <em>in</em>dependencies) of the model, without capturing the precise <em>form</em> of these functions.
For example, while the graphical model shown above faithfully represents the probability distribution encoded by the WebPPL program, it captures the <em>noisy-OR</em> form of the causal dependencies only implicitly.
As a result, the CPTs provide a less compact representation of the conditional probabilities than the WebPPL model.
For instance, the CPT for <code class="highlighter-rouge">cough</code> specifies 4 parameters – one for each pair of values of <code class="highlighter-rouge">lungDisease</code> and <code class="highlighter-rouge">cold</code> (the second entry in each row is determined by the constraint that the conditional distribution of <code class="highlighter-rouge">cough</code> must sum to 1).
In contrast, the <code class="highlighter-rouge">var</code> statement for <code class="highlighter-rouge">cough</code> in WebPPL specifies only 3 parameters: the base rate of <code class="highlighter-rouge">cough</code>, and the strength with which <code class="highlighter-rouge">lungDisease</code> and <code class="highlighter-rouge">cold</code> cause <code class="highlighter-rouge">cough</code>.
This difference becomes more pronounced for noisy-OR relations with many causes – the size of the CPT for a node will be exponential in the number of parents, while the number of terms in the noisy-OR expression in WebPPL for that node will be linear in the number of causal dependencies (why?).
As we will see, this has important implications for the ability to learn the values of the parameters from data.</p>

<p>More complicated generative models, which can be expressed as probabilistic programs, often don’t have such a graphical model (or rather they have many approximations, none of which captures all independencies).
Recursive models generally give rise to such ambiguous (or loopy) Bayes nets.</p>

<p>Test your knowledge: <a href="../exercises/dependence.html">Exercises</a></p>

<p>Reading &amp; Discussion: <a href="../readings/dependence.html">Readings</a></p>


<!--
<a href="Further Reading">/readings/dependence.md</a>
<a href="Exercises">/exercises/dependence.md</a>
-->



	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
	

	
		Next chapter: <a href="conditional-dependence.html">5. Conditional dependence</a>
		

<!-- put big scripts at end so we don't block page load -->
<script src="../assets/js/webppl.min.js"></script>
<script src="../assets/js/webppl-editor.min.js"></script>
<script src="../assets/js/webppl-viz.min.js"></script>


    </div>

  </body>

<!-- Mirrored from probmods.org/chapters/dependence.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 04 Feb 2020 14:08:30 GMT -->
</html>
